{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "2.7.17-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2,
  "kernelspec": {
   "name": "python37564bitd4e7769e220b462f922257447f5a3ddd",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konvoluční neuronové sítě\n",
    "\n",
    "\n",
    "\n",
    "Jaké jsou výhody konvolučních sítí? Zkuste si otevřít [https://playground.tensorflow.org/](https://playground.tensorflow.org/). Jedná se o jednoduchou MLP síť, která se snaží klasifikovat data na vstupu. Pokud vybete nalevo jiný dataset, uvidíte, že klasifikace není možná. Pokud ale vstupem MLP sítě bude nějaký jiný příznak než jen x1 a x2 (např kvadráty), po nějakém době se NN natrénuje na požadovaný výstup. V komplexních datech je to ještě složitější. Nešlo by to ale dělat nějak automaticky? K tomu slouží tzv. konvoluční sítě (a hluboké neuronové sítě - DNN). První takovou síť představil v roce 1997 Yann LeChun (síť LeNet) a tento krok se stal milníkem, který změnil pohled na strojové učení. V tomto cvičení se na takovou NN síť podíváme.\n",
    "\n",
    "## Práce s neuronovou sítí\n",
    "Předpokládá se, že jste si prošli řešení první [mlp.ipynb](mlp.ipynb) MLP sítě. V této ukázce zpracujeme síť konvoluční ve variantě LeNet.\n",
    "\n",
    "V prvním kroce musíme načíst požadované knihovny. Budeme pracovat s knihovnou Tensorflow a rozhraním Keras, které je v nové verzi TF 2.0. Varování týkající se zastaralosti volání funkcí ``numpy`` můžeme ignorovat, jsou způsobeny využitím starší verze TensorFlow 1.14.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knihovny jsou úspěšně načtené. Dalším krokem bude znovu stáhnout dataset MNIST. Tento dataset je rozdělen na trénovací data a testovací data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(60000, 28, 28) (10000, 28, 28)\n"
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní se můžeme dát do konstrukce sítě. Deklarujeme si parametry jako jsou počet batchů (dávek) a počet epoch, po které budeme trénovat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Převedeme trénovací data do formátu float čísel 0 - 1. Zde je první **rozdíl vůči MLP síti**. Vstupní obrázky necháme v rozměru 28x28, ale přidáme ještě jednu dimenzi - barevný kanál (v našem případě je jen 1 barva - takže data se prakticky nezmění)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "60000 train samples\n10000 test samples\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(10000, 10)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# reshape nedelame, protoze chceme, aby se jednalo o obrazky 28x28 kvuli konvoluci\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vytvoříme síť konvolučních vrstev následovaných plně propojenými. Každá konvoluce má určeno, jak velký je filtr a kolik těchto filtrů ve výsledku je. Podle nastavení okrajů se buď obrázek zmenší (šířka - velikost filtru + 1) nebo se kraje doplní nulami. Protože jsou výsledné obrázky příznaků (features) moc velké, použije se zmenšení pomocí ```AveragePooling2D``` vrstvy - tato vrstva rozdělí obrázek do čtvrečků 2x2 a vypočítá průměr. Ve svých výpočtech počtu operací tuto operaci ignorujte. V další vrstvě se 6 feature obrázků zase prožene 3x3 filtry. Pozor, na vstupu je 6 kanálů - pro každý filtr a vstupní kanál máme vlastní konvoluční filtr (v druhé vstvě máme tedy 6 * 16 3x3 filtrů), jejichž výstupy se pro všechny kanály sečtou (jak je naznačeno na obrázku)\n",
    "![https://i.stack.imgur.com/uDgke.gif](https://i.stack.imgur.com/uDgke.gif)\n",
    "\n",
    "Výstup druhého filtru je zase zmenšen. Pomocí Flatten vrstvy dojde k překódování 2D obrázků o 16 kanálech na 1D vektor příznaků (pouhým přeskládáním) a tento vektor je vstupem do závěrečné části, která je tvořena plně propojenými sítěmi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /home/vojta/.local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 26, 26, 6)         60        \n_________________________________________________________________\naverage_pooling2d (AveragePo (None, 13, 13, 6)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 11, 11, 16)        880       \n_________________________________________________________________\naverage_pooling2d_1 (Average (None, 5, 5, 16)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 400)               0         \n_________________________________________________________________\ndense (Dense)                (None, 120)               48120     \n_________________________________________________________________\ndense_1 (Dense)              (None, 84)                10164     \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                850       \n=================================================================\nTotal params: 60,074\nTrainable params: 60,074\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28,28, 1)))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "model.add(layers.Dense(units=10, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní můžeme model zkompilovat a spustit trénování. Tato operace může zabrat nějaký čas, zejména pokud nemáte GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/5\n60000/60000 [==============================] - 3s 58us/sample - loss: 0.4560 - acc: 0.8640 - val_loss: 0.2203 - val_acc: 0.9256\nEpoch 2/5\n60000/60000 [==============================] - 3s 56us/sample - loss: 0.1460 - acc: 0.9554 - val_loss: 0.1225 - val_acc: 0.9580\nEpoch 3/5\n60000/60000 [==============================] - 3s 56us/sample - loss: 0.0896 - acc: 0.9728 - val_loss: 0.0810 - val_acc: 0.9736\nEpoch 4/5\n60000/60000 [==============================] - 3s 56us/sample - loss: 0.0677 - acc: 0.9788 - val_loss: 0.0511 - val_acc: 0.9830\nEpoch 5/5\n60000/60000 [==============================] - 3s 56us/sample - loss: 0.0547 - acc: 0.9830 - val_loss: 0.0480 - val_acc: 0.9851\n"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model je nyní natrénovaný (na poměrně malý počet epoch). Nyní jej můžeme uložit nebo použít na jednom konkrétním obrázku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test loss: 0.047968082719598897\nTest accuracy: 0.9851\n"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ]
}